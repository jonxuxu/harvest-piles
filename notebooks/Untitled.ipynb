{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b49b42-ea4d-4f13-9c4d-18d3b40de97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/atlas2/u/jonxuxu/harvest-piles/src')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from config import Swin_Pretrain\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    "    ToPILImage,\n",
    "    Normalize,\n",
    ")\n",
    "from transformers import Swinv2Config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df6b1b71-4d06-42c3-99c9-224de0da0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Swin_Pretrain()\n",
    "pretrained_model_path = \"microsoft/swinv2-base-patch4-window8-256\"\n",
    "model_config = Swinv2Config.from_pretrained(pretrained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c305814d-19ec-422a-9763-87c97b4d77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class SkysatUnlabelled(Dataset):\n",
    "    def __init__(self, filenames, image_dir, transform):\n",
    "        self.x = filenames\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = os.path.join(self.image_dir, self.x[index])\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return self.transform(image)\n",
    "\n",
    "def create_SkysatUnlabelled_dataset(csv_file, image_dir, transform, train_split):\n",
    "    df = pd.read_csv(csv_file, usecols=[\"filename\"])\n",
    "    filename_list = df[\"filename\"].tolist()\n",
    "    train_size = int(len(filename_list) * train_split)\n",
    "    train_examples = filename_list[:train_size]\n",
    "    test_examples = filename_list[train_size:]\n",
    "    print(type(test_examples))\n",
    "\n",
    "    return SkysatUnlabelled(train_examples, image_dir, transform), SkysatUnlabelled(\n",
    "        test_examples, image_dir, transform\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2330851-c3b3-4237-b99c-cb96fdb689bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "class MaskGenerator:\n",
    "    \"\"\"\n",
    "    A class to generate boolean masks for the pretraining task.\n",
    "\n",
    "    A mask is a 1D tensor of shape (image_size / model_patch_size)**2 where the value is either 0 or 1,\n",
    "    where 1 indicates \"masked\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size=192, mask_patch_size=32, model_patch_size=4, mask_ratio=0.6\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.mask_patch_size = mask_patch_size\n",
    "        self.model_patch_size = model_patch_size\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "        if self.input_size % self.mask_patch_size != 0:\n",
    "            raise ValueError(\"Input size must be divisible by mask patch size\")\n",
    "        if self.mask_patch_size % self.model_patch_size != 0:\n",
    "            raise ValueError(\"Mask patch size must be divisible by model patch size\")\n",
    "\n",
    "        self.rand_size = self.input_size // self.mask_patch_size\n",
    "        self.scale = self.mask_patch_size // self.model_patch_size\n",
    "\n",
    "        self.token_count = self.rand_size**2\n",
    "        self.mask_count = int(np.ceil(self.token_count * self.mask_ratio))\n",
    "\n",
    "    def __call__(self):\n",
    "        mask_idx = np.random.permutation(self.token_count)[: self.mask_count]\n",
    "        mask = np.zeros(self.token_count, dtype=int)\n",
    "        mask[mask_idx] = 1\n",
    "\n",
    "        mask = mask.reshape((self.rand_size, self.rand_size))\n",
    "        mask = mask.repeat(self.scale, axis=0).repeat(self.scale, axis=1)\n",
    "\n",
    "        return torch.tensor(mask.flatten())\n",
    "\n",
    "mask_generator = MaskGenerator(\n",
    "    input_size=model_config.image_size,\n",
    "    mask_patch_size=config.mask_patch_size,\n",
    "    model_patch_size=config.model_patch_size,\n",
    "    mask_ratio=config.mask_ratio,\n",
    ")\n",
    "\n",
    "transforms = Compose(\n",
    "    [\n",
    "        ToPILImage(),\n",
    "        Resize((model_config.image_size, model_config.image_size)),\n",
    "        # torchvision.transforms.RandomHorizontalFlip(),\n",
    "        # torchvision.transforms.RandomVerticalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            mean=[0.412, 0.368, 0.326], std=[0.110, 0.097, 0.098]\n",
    "        ),  # our dataset vals\n",
    "    ]\n",
    ")\n",
    "\n",
    "def preprocess_images(x):\n",
    "    \"\"\"Preprocess a batch of images by applying transforms + creating a corresponding mask, indicating\n",
    "    which patches to mask.\"\"\"\n",
    "    out = {\n",
    "        \"pixel_values\": transforms(x),\n",
    "        \"mask\": mask_generator(),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "train_set, test_set = create_SkysatUnlabelled_dataset(\n",
    "    os.path.join(config.dataset_path, \"merged.csv\"),\n",
    "    os.path.join(config.dataset_path, \"merged\"),\n",
    "    preprocess_images,\n",
    "    config.train_val_split,\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_set, batch_size=config.per_device_train_batch_size)\n",
    "test_dl = DataLoader(test_set, batch_size=config.per_device_eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20a73abb-d0dd-4fcb-abb5-a743527edfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = iter(test_dl)\n",
    "batch = next(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92965e3e-ee44-4d29-b2e6-7c3221053083",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5a6898f-cca6-4675-b1a8-c43a661f71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ab29e-5c85-4b11-b1fc-3919c71083f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
